#!/usr/bin/env python3
"""
ZOPTYMALIZOWANY GEOCODER - WYDAJNO≈öƒÜ I ASYNC
Ulepszona wersja z async/await, connection pooling i batch processing
"""
import asyncio
import aiohttp
import logging
import time
import sys
import os
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import json

# Dodaj g≈Ç√≥wny katalog do ≈õcie≈ºki
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from supabase_utils import get_supabase_client

# Konfiguracja logowania
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Konfiguracja geocodingu
NOMINATIM_BASE_URL = "https://nominatim.openstreetmap.org/search"
DELAY_BETWEEN_REQUESTS = 0.5  # Zmniejszone op√≥≈∫nienie dla async
MAX_RETRIES = 2  # Zmniejszone retry dla szybko≈õci
MAX_CONCURRENT_REQUESTS = 5  # Maksymalna liczba r√≥wnoczesnych request√≥w
BATCH_SIZE = 100  # Wiƒôkszy batch size
CONNECTION_TIMEOUT = 10
READ_TIMEOUT = 15

class OptimizedGeocoder:
    """Zoptymalizowany geocoder z async/await"""
    
    def __init__(self):
        self.session = None
        self.semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        self.headers = {
            'User-Agent': 'Polish Real Estate Scraper/2.0 (optimized version)'
        }
        
    async def __aenter__(self):
        """Async context manager entry"""
        connector = aiohttp.TCPConnector(
            limit=20,  # Connection pool size
            limit_per_host=10,
            ttl_dns_cache=300,
            use_dns_cache=True,
        )
        
        timeout = aiohttp.ClientTimeout(
            total=CONNECTION_TIMEOUT + READ_TIMEOUT,
            connect=CONNECTION_TIMEOUT,
            sock_read=READ_TIMEOUT
        )
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers=self.headers
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        if self.session:
            await self.session.close()
    
    def build_optimized_query(self, address_data: Dict) -> str:
        """Buduje zoptymalizowane zapytanie - tylko najwa≈ºniejsze elementy"""
        components = []
        
        # 1. Ulica (bez prefiks√≥w)
        if address_data.get('street_name'):
            street = address_data['street_name']
            # Usu≈Ñ prefiksy
            for prefix in ['Ul. ', 'Al. ', 'Pl. ', 'Os. ', 'ul. ', 'al. ', 'pl. ', 'os. ']:
                street = street.replace(prefix, '')
            if street.strip():
                components.append(street.strip())
        
        # 2. Miasto (obowiƒÖzkowe)
        if address_data.get('city'):
            city = address_data['city']
            # Poprawki nazw miast
            city_fixes = {
                'Gda≈Ñski': 'Pruszcz Gda≈Ñski',
                '≈Åomianki': '≈Åomianki',
                'Ole≈õnica': 'Ole≈õnica',
            }
            city = city_fixes.get(city, city)
            components.append(city)
        
        # 3. Zawsze dodaj "Polska"
        components.append("Polska")
        
        query = ", ".join(components)
        logger.debug(f"Zoptymalizowane zapytanie: {query}")
        return query
    
    def build_fallback_query(self, address_data: Dict) -> str:
        """Buduje zapytanie fallback - tylko miasto + Polska"""
        if address_data.get('city'):
            city = address_data['city']
            city_fixes = {'Gda≈Ñski': 'Pruszcz Gda≈Ñski'}
            city = city_fixes.get(city, city)
            return f"{city}, Polska"
        return "Polska"
    
    async def geocode_single_async(self, query: str, fallback_query: str = None) -> Optional[Tuple[float, float]]:
        """Async geocoding pojedynczego adresu"""
        async with self.semaphore:  # Limit concurrent requests
            params = {
                'q': query,
                'format': 'json',
                'limit': 1,
                'countrycodes': 'pl',
                'addressdetails': 0,  # Wy≈ÇƒÖcz szczeg√≥≈Çy dla szybko≈õci
                'extratags': 0       # Wy≈ÇƒÖcz dodatkowe tagi
            }
            
            # Pr√≥ba 1: G≈Ç√≥wne zapytanie
            for attempt in range(MAX_RETRIES):
                try:
                    async with self.session.get(NOMINATIM_BASE_URL, params=params) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            if data and len(data) > 0:
                                result = data[0]
                                lat = float(result['lat'])
                                lon = float(result['lon'])
                                
                                # Walidacja granic Polski
                                if 49.0 <= lat <= 54.9 and 14.1 <= lon <= 24.2:
                                    logger.debug(f"Znaleziono wsp√≥≈Çrzƒôdne: {lat:.6f}, {lon:.6f}")
                                    return (lat, lon)
                                else:
                                    logger.warning(f"Wsp√≥≈Çrzƒôdne poza PolskƒÖ: {lat}, {lon}")
                        
                except asyncio.TimeoutError:
                    logger.warning(f"Timeout dla zapytania: {query} (pr√≥ba {attempt + 1})")
                    if attempt < MAX_RETRIES - 1:
                        await asyncio.sleep(1)
                except Exception as e:
                    logger.error(f"B≈ÇƒÖd geocodingu (pr√≥ba {attempt + 1}): {e}")
                    if attempt < MAX_RETRIES - 1:
                        await asyncio.sleep(1)
            
            # Pr√≥ba 2: Fallback query
            if fallback_query and fallback_query != query:
                logger.debug(f"Pr√≥ba fallback: {fallback_query}")
                params['q'] = fallback_query
                
                try:
                    async with self.session.get(NOMINATIM_BASE_URL, params=params) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            if data and len(data) > 0:
                                result = data[0]
                                lat = float(result['lat'])
                                lon = float(result['lon'])
                                
                                if 49.0 <= lat <= 54.9 and 14.1 <= lon <= 24.2:
                                    logger.debug(f"Znaleziono wsp√≥≈Çrzƒôdne (fallback): {lat:.6f}, {lon:.6f}")
                                    return (lat, lon)
                                    
                except Exception as e:
                    logger.error(f"B≈ÇƒÖd fallback geocodingu: {e}")
            
            # Op√≥≈∫nienie miƒôdzy requestami
            await asyncio.sleep(DELAY_BETWEEN_REQUESTS)
            
            logger.warning(f"Brak wynik√≥w geocodingu dla: {query}")
            return None
    
    async def geocode_batch_async(self, addresses: List[Dict]) -> List[Tuple[int, Optional[Tuple[float, float]]]]:
        """Async geocoding ca≈Çego batcha"""
        tasks = []
        
        for address in addresses:
            address_id = address['id']
            
            # Sprawd≈∫ czy ju≈º ma wsp√≥≈Çrzƒôdne
            if address.get('latitude') and address.get('longitude'):
                tasks.append(asyncio.create_task(self._return_existing(address_id, address)))
                continue
            
            # Buduj zapytania
            main_query = self.build_optimized_query(address)
            fallback_query = self.build_fallback_query(address)
            
            if not main_query or main_query == "Polska":
                tasks.append(asyncio.create_task(self._return_none(address_id)))
                continue
            
            # Dodaj task geocodingu
            task = asyncio.create_task(self._geocode_with_id(address_id, main_query, fallback_query))
            tasks.append(task)
        
        # Wykonaj wszystkie taski r√≥wnocze≈õnie
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filtruj wyjƒÖtki
        valid_results = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"B≈ÇƒÖd w batch geocoding: {result}")
                valid_results.append((None, None))
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def _return_existing(self, address_id: int, address: Dict) -> Tuple[int, Optional[Tuple[float, float]]]:
        """Zwraca istniejƒÖce wsp√≥≈Çrzƒôdne"""
        lat = address.get('latitude')
        lon = address.get('longitude')
        return (address_id, (lat, lon) if lat and lon else None)
    
    async def _return_none(self, address_id: int) -> Tuple[int, Optional[Tuple[float, float]]]:
        """Zwraca None dla pustych adres√≥w"""
        return (address_id, None)
    
    async def _geocode_with_id(self, address_id: int, main_query: str, fallback_query: str) -> Tuple[int, Optional[Tuple[float, float]]]:
        """Geocoding z ID adresu"""
        coordinates = await self.geocode_single_async(main_query, fallback_query)
        return (address_id, coordinates)

def get_addresses_without_coordinates_optimized(limit: int = 100) -> List[Dict]:
    """Zoptymalizowane pobieranie adres√≥w bez wsp√≥≈Çrzƒôdnych"""
    supabase = get_supabase_client()
    
    try:
        # Pobierz tylko potrzebne kolumny dla wydajno≈õci
        result = supabase.table("addresses").select(
            "id, city, street_name, district, latitude, longitude"
        ).is_('latitude', 'null').is_('longitude', 'null').limit(limit).execute()
        
        if result.data:
            logger.info(f"üìä Pobrano {len(result.data)} adres√≥w bez wsp√≥≈Çrzƒôdnych")
            return result.data
        else:
            logger.info("‚úÖ Wszystkie adresy majƒÖ ju≈º wsp√≥≈Çrzƒôdne")
            return []
            
    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd pobierania adres√≥w: {e}")
        return []

def update_coordinates_batch(coordinates_data: List[Tuple[int, Optional[Tuple[float, float]]]]) -> Dict[str, int]:
    """Batch update wsp√≥≈Çrzƒôdnych w bazie danych"""
    supabase = get_supabase_client()
    stats = {"success": 0, "failed": 0, "skipped": 0}
    
    # Przygotuj dane do batch update
    updates = []
    for address_id, coordinates in coordinates_data:
        if coordinates:
            lat, lon = coordinates
            updates.append({
                "id": address_id,
                "latitude": lat,
                "longitude": lon
            })
    
    if not updates:
        stats["skipped"] = len(coordinates_data)
        return stats
    
    try:
        # Batch update - znacznie szybsze ni≈º pojedyncze update
        for update_data in updates:
            try:
                result = supabase.table("addresses").update({
                    "latitude": update_data["latitude"],
                    "longitude": update_data["longitude"]
                }).eq("id", update_data["id"]).execute()
                
                if result.data:
                    stats["success"] += 1
                else:
                    stats["failed"] += 1
                    
            except Exception as e:
                logger.error(f"B≈ÇƒÖd update adresu {update_data['id']}: {e}")
                stats["failed"] += 1
        
        # Policz pominiƒôte
        stats["skipped"] = len(coordinates_data) - len(updates)
        
        logger.info(f"‚úÖ Batch update: {stats['success']} sukces, {stats['failed']} b≈Çƒôd√≥w, {stats['skipped']} pominiƒôtych")
        
    except Exception as e:
        logger.error(f"‚ùå B≈ÇƒÖd batch update: {e}")
        stats["failed"] = len(updates)
        stats["skipped"] = len(coordinates_data) - len(updates)
    
    return stats

async def run_optimized_geocoding(max_addresses: int = None, batch_size: int = BATCH_SIZE) -> None:
    """G≈Ç√≥wna funkcja zoptymalizowanego geocodingu"""
    print("="*80)
    print("üöÄ ZOPTYMALIZOWANY GEOCODER - ASYNC + BATCH PROCESSING")
    print("="*80)
    print(f"üìä Parametry:")
    print(f"   ‚Ä¢ Rozmiar batcha: {batch_size}")
    print(f"   ‚Ä¢ Maksymalne adresy: {max_addresses or 'wszystkie'}")
    print(f"   ‚Ä¢ R√≥wnoczesne requesty: {MAX_CONCURRENT_REQUESTS}")
    print(f"   ‚Ä¢ Op√≥≈∫nienie: {DELAY_BETWEEN_REQUESTS}s")
    print("="*80)
    
    total_stats = {
        "processed": 0,
        "success": 0,
        "failed": 0,
        "skipped": 0
    }
    
    processed_count = 0
    batch_number = 1
    start_time = time.time()
    
    async with OptimizedGeocoder() as geocoder:
        while True:
            # Oblicz limit dla tego batcha
            remaining_limit = batch_size
            if max_addresses:
                remaining_limit = min(batch_size, max_addresses - processed_count)
                if remaining_limit <= 0:
                    break
            
            # Pobierz batch adres√≥w
            addresses = get_addresses_without_coordinates_optimized(limit=remaining_limit)
            
            if not addresses:
                print("‚úÖ Wszystkie adresy majƒÖ ju≈º wsp√≥≈Çrzƒôdne!")
                break
            
            print(f"\nüîÑ BATCH {batch_number} - {len(addresses)} adres√≥w")
            batch_start = time.time()
            
            # Async geocoding ca≈Çego batcha
            coordinates_results = await geocoder.geocode_batch_async(addresses)
            
            # Batch update w bazie danych
            batch_stats = update_coordinates_batch(coordinates_results)
            
            # Aktualizuj statystyki
            for key in total_stats:
                if key in batch_stats:
                    total_stats[key] += batch_stats[key]
            
            total_stats["processed"] += len(addresses)
            processed_count += len(addresses)
            
            # Statystyki batcha
            batch_time = time.time() - batch_start
            addresses_per_second = len(addresses) / batch_time if batch_time > 0 else 0
            
            print(f"   ‚úÖ Sukces: {batch_stats['success']}")
            print(f"   ‚ùå B≈Çƒôdy: {batch_stats['failed']}")
            print(f"   ‚è≠Ô∏è Pominiƒôte: {batch_stats['skipped']}")
            print(f"   ‚è±Ô∏è Czas: {batch_time:.1f}s ({addresses_per_second:.1f} adr/s)")
            
            # Sprawd≈∫ limity
            if max_addresses and processed_count >= max_addresses:
                break
            
            if len(addresses) < batch_size:
                print(f"üìÑ Ostatni batch")
                break
            
            batch_number += 1
            
            # Kr√≥tkie op√≥≈∫nienie miƒôdzy batchami
            await asyncio.sleep(1)
    
    # Podsumowanie ko≈Ñcowe
    total_time = time.time() - start_time
    addresses_per_second = total_stats["processed"] / total_time if total_time > 0 else 0
    
    print("\n" + "="*80)
    print("üìä PODSUMOWANIE ZOPTYMALIZOWANEGO GEOCODINGU")
    print("="*80)
    print(f"üìã ≈ÅƒÖcznie przetworzonych: {total_stats['processed']}")
    print(f"‚úÖ Pomy≈õlnie geocodowanych: {total_stats['success']}")
    print(f"‚ùå B≈Çƒôd√≥w geocodingu: {total_stats['failed']}")
    print(f"‚è≠Ô∏è Pominiƒôtych: {total_stats['skipped']}")
    print(f"‚è±Ô∏è Ca≈Çkowity czas: {total_time:.1f}s")
    print(f"üöÄ Wydajno≈õƒá: {addresses_per_second:.1f} adres√≥w/sekundƒô")
    
    if total_stats['processed'] > 0:
        success_rate = (total_stats['success'] / total_stats['processed']) * 100
        print(f"üìà Skuteczno≈õƒá: {success_rate:.1f}%")
    
    print("="*80)

if __name__ == "__main__":
    """Test zoptymalizowanego geocodera"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Zoptymalizowany geocoder')
    parser.add_argument('--test', action='store_true', help='Uruchom test')
    parser.add_argument('--update', action='store_true', help='Aktualizuj wsp√≥≈Çrzƒôdne')
    parser.add_argument('--batch-size', type=int, default=BATCH_SIZE, help=f'Rozmiar batcha (domy≈õlnie: {BATCH_SIZE})')
    parser.add_argument('--max-addresses', type=int, help='Maksymalna liczba adres√≥w')
    
    args = parser.parse_args()
    
    try:
        if args.test:
            print("üß™ TEST ZOPTYMALIZOWANEGO GEOCODERA")
            print("="*60)
            
            # Test z ma≈ÇƒÖ pr√≥bkƒÖ
            asyncio.run(run_optimized_geocoding(max_addresses=10, batch_size=5))
            
        elif args.update:
            asyncio.run(run_optimized_geocoding(
                max_addresses=args.max_addresses,
                batch_size=args.batch_size
            ))
        else:
            print("üöÄ ZOPTYMALIZOWANY GEOCODER")
            print("U≈ºycie:")
            print("  python geocoder_optimized.py --test           # Test na 10 adresach")
            print("  python geocoder_optimized.py --update         # Aktualizuj wszystkie")
            print("  python geocoder_optimized.py --update --max-addresses 500  # Limit")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Przerwano przez u≈ºytkownika")
    except Exception as e:
        print(f"\n‚ùå B≈ÇƒÖd krytyczny: {e}")
        logger.error(f"B≈ÇƒÖd w geocoder_optimized: {e}", exc_info=True) 